{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Lambda, Dropout\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vandermonde_multiplier(dim_x, m):\n",
    "    dim_v = (m + 1)**dim_x\n",
    "    \n",
    "    v_mult_row = np.zeros((dim_x,))\n",
    "    v_mult = np.zeros((dim_v, dim_x))\n",
    "    \n",
    "    for i_row in range(1, dim_v):\n",
    "        v_mult_row[0] += 1\n",
    "        \n",
    "        for i_dim in range(dim_x - 1):\n",
    "            if v_mult_row[i_dim] >= (m + 1):\n",
    "                v_mult_row[i_dim + 1] += v_mult_row[i_dim] // (m + 1)\n",
    "                v_mult_row[i_dim] %= (m + 1)\n",
    "        \n",
    "        v_mult[i_row, :] = v_mult_row\n",
    "        \n",
    "    return v_mult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_list_from_file(file_path, file_name):\n",
    "    edges = []\n",
    "    with open(file_path + '/' + file_name) as data_file:\n",
    "        data_reader = csv.reader(data_file, delimiter='\\t')\n",
    "        \n",
    "        n_user = 0\n",
    "        n_item = 0\n",
    "        for row in data_reader:\n",
    "            user, item, value = int(row[0]), int(row[1]), float(row[2])\n",
    "            edges += [( user, item, value )]\n",
    "            \n",
    "            n_user = max([n_user, user])\n",
    "            n_item = max([n_item, item])\n",
    "\n",
    "    return edges, n_user, n_item\n",
    "\n",
    "\n",
    "def get_observed_dic_from_edge_list(edges):\n",
    "    users_dic = {}\n",
    "    items_dic = {}\n",
    "    user_item_dic = {}\n",
    "    for user, item, value in edges:\n",
    "        \n",
    "        user_item_dic[(user, item)] = value\n",
    "\n",
    "        # update users_dic\n",
    "        if user in users_dic:\n",
    "            users_dic[user] += [item]\n",
    "        else:\n",
    "            users_dic[user] = [item]\n",
    "\n",
    "        # update items_dic\n",
    "        if item in items_dic:\n",
    "            items_dic[item] += [user]\n",
    "        else:\n",
    "            items_dic[item] = [user]\n",
    "            \n",
    "\n",
    "    return users_dic, items_dic, user_item_dic\n",
    "\n",
    "\n",
    "def get_input_output(n_item, n_user, user_item_dic):\n",
    "    x_one_hot = np.eye(n_item)\n",
    "    \n",
    "    s_full = np.ones((n_item, n_user))*-1\n",
    "    for user_item, val in user_item_dic.items():\n",
    "        user, item = user_item\n",
    "        s_full[item - 1, user - 1] = val\n",
    "        \n",
    "    return x_one_hot, s_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = '../smooth-reconstruction-of-preference-function/data/ml-100k'\n",
    "\n",
    "_, n_user, n_item = get_edge_list_from_file(load_path, 'u.data')\n",
    "edges_tr, _, _ = get_edge_list_from_file(load_path, 'u3.base')\n",
    "edges_te, _, _ = get_edge_list_from_file(load_path, 'u3.test')\n",
    "\n",
    "users_dic_tr, items_dic_tr, r_tr = get_observed_dic_from_edge_list(edges_tr)\n",
    "users_dic_te, items_dic_te, r_te = get_observed_dic_from_edge_list(edges_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot_tr, s_full_tr = get_input_output(n_item, n_user, r_tr)\n",
    "x_one_hot_te, s_full_te = get_input_output(n_item, n_user, r_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n"
     ]
    }
   ],
   "source": [
    "dim_x = 5\n",
    "m = 5\n",
    "\n",
    "v_mult = vandermonde_multiplier(dim_x, m)\n",
    "\n",
    "dim_v = v_mult.shape[0]\n",
    "\n",
    "print(dim_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1682)]            0         \n",
      "_________________________________________________________________\n",
      "x (Dense)                    (None, 5)                 8410      \n",
      "_________________________________________________________________\n",
      "v_mult (Dense)               (None, 7776)              38880     \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 7776)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7776)              0         \n",
      "_________________________________________________________________\n",
      "a (Dense)                    (None, 943)               7332768   \n",
      "=================================================================\n",
      "Total params: 7,380,058\n",
      "Trainable params: 7,341,178\n",
      "Non-trainable params: 38,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_one_hot_layer = Input(shape=(n_item,))\n",
    "x_layer = Dense(dim_x,\n",
    "                use_bias=False,\n",
    "                trainable=True,\n",
    "                kernel_initializer=RandomUniform(minval=-1, maxval=1),\n",
    "                kernel_constraint='non_neg',\n",
    "                name='x')(input_one_hot_layer)\n",
    "\n",
    "v_mult_layer = Dense(dim_v,\n",
    "                     use_bias=False,\n",
    "                     trainable=False,\n",
    "                     name='v_mult')(x_layer)\n",
    "\n",
    "v_cos_layer = Lambda(lambda x: K.cos(np.pi*x))(v_mult_layer)\n",
    "\n",
    "drp_v_layer = Dropout(0.3)(v_cos_layer)\n",
    "\n",
    "a_layer = Dense(n_user,\n",
    "                use_bias=False,\n",
    "                kernel_initializer=RandomNormal(mean=0, stddev=1e-3),\n",
    "                name='a')(drp_v_layer)\n",
    "\n",
    "mdl = Model(inputs=input_one_hot_layer, outputs=a_layer)\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set v_layer weights\n",
    "mdl.get_layer(name='v_mult').set_weights([v_mult.T])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask = y_true > 0\n",
    "    diff = y_true - y_pred\n",
    "    \n",
    "    return K.mean(K.square(diff[mask]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.compile(loss=custom_loss,\n",
    "            optimizer = 'RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "53/53 [==============================] - 7s 139ms/step - loss: 11.2107 - val_loss: 8.7769\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 8s 153ms/step - loss: 4.4741 - val_loss: 9.3757\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 11s 199ms/step - loss: 3.6175 - val_loss: 9.2595\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 9s 161ms/step - loss: 3.9382 - val_loss: 9.8067\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 8s 156ms/step - loss: 3.7083 - val_loss: 9.5769\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 9s 164ms/step - loss: 3.7294 - val_loss: 9.5805\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 9s 161ms/step - loss: 3.9789 - val_loss: 9.6836\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 9s 163ms/step - loss: 3.6627 - val_loss: 9.5352\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 9s 178ms/step - loss: 4.0041 - val_loss: 9.5377\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 12s 230ms/step - loss: 3.8667 - val_loss: 9.6942\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 9s 178ms/step - loss: 3.9030 - val_loss: 9.5095\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 10s 180ms/step - loss: 3.7577 - val_loss: 9.3793\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 10s 186ms/step - loss: 3.9440 - val_loss: 9.5022\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 10s 181ms/step - loss: 4.0084 - val_loss: 9.9193\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 11s 207ms/step - loss: 3.7996 - val_loss: 9.5083\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 13s 236ms/step - loss: 4.1880 - val_loss: 9.7753\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 3.9787 - val_loss: 9.5288\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 10s 192ms/step - loss: 3.9350 - val_loss: 9.8090\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 10s 194ms/step - loss: 3.9336 - val_loss: 10.2232\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 10s 188ms/step - loss: 4.2395 - val_loss: 10.0579\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 13s 250ms/step - loss: 3.8337 - val_loss: 9.6817\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 11s 199ms/step - loss: 4.1231 - val_loss: 9.9441\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 10s 195ms/step - loss: 4.1817 - val_loss: 10.1411\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 10s 194ms/step - loss: 4.2301 - val_loss: 10.5184\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 11s 210ms/step - loss: 4.0180 - val_loss: 10.3076\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 13s 251ms/step - loss: 4.3095 - val_loss: 9.7611\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 19s 350ms/step - loss: 3.9833 - val_loss: 10.1131\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 20s 383ms/step - loss: 4.2614 - val_loss: 10.3153\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 18s 343ms/step - loss: 4.3376 - val_loss: 10.8777\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 16s 309ms/step - loss: 4.2050 - val_loss: 10.2066\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 12s 226ms/step - loss: 4.0945 - val_loss: 10.5634\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 4.3655 - val_loss: 10.0831\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 15s 290ms/step - loss: 4.1460 - val_loss: 10.2785\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 4.4094 - val_loss: 10.5269\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 15s 274ms/step - loss: 4.2438 - val_loss: 10.6211\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 17s 314ms/step - loss: 4.2847 - val_loss: 10.4093\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 20s 376ms/step - loss: 4.2286 - val_loss: 10.0187\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 4.2449 - val_loss: 10.4611\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 13s 241ms/step - loss: 4.2917 - val_loss: 10.5051\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 4.3068 - val_loss: 10.4585\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 18s 341ms/step - loss: 4.3833 - val_loss: 10.4927\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 16s 296ms/step - loss: 4.3028 - val_loss: 10.2780\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 20s 372ms/step - loss: 4.4225 - val_loss: 10.7025\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 20s 378ms/step - loss: 4.4282 - val_loss: 10.3470\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 14s 256ms/step - loss: 4.3401 - val_loss: 10.6770\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 16s 295ms/step - loss: 4.5015 - val_loss: 10.2938\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 4.3324 - val_loss: 10.4014\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 15s 281ms/step - loss: 4.5995 - val_loss: 10.5102\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 12s 229ms/step - loss: 4.3559 - val_loss: 10.6381\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 15s 286ms/step - loss: 4.4548 - val_loss: 10.5039\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 4.6755 - val_loss: 10.4963\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 17s 330ms/step - loss: 4.4105 - val_loss: 10.9552\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 12s 233ms/step - loss: 4.5393 - val_loss: 10.6406\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 10s 194ms/step - loss: 4.5073 - val_loss: 10.4161\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 4.4466 - val_loss: 10.8961\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 13s 248ms/step - loss: 4.5846 - val_loss: 10.8101\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 11s 208ms/step - loss: 4.7216 - val_loss: 10.5075\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 12s 230ms/step - loss: 4.5276 - val_loss: 10.6894\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 12s 228ms/step - loss: 4.7122 - val_loss: 11.2288\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 11s 215ms/step - loss: 4.6098 - val_loss: 11.1334\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 4.5811 - val_loss: 10.7724\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 13s 243ms/step - loss: 4.7316 - val_loss: 10.6317\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 13s 245ms/step - loss: 4.6420 - val_loss: 10.6612\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 4.5481 - val_loss: 10.5905\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 23s 427ms/step - loss: 4.6563 - val_loss: 11.1573\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 14s 271ms/step - loss: 4.7240 - val_loss: 10.8391\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 12s 228ms/step - loss: 4.5589 - val_loss: 10.8578\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 16s 302ms/step - loss: 4.7377 - val_loss: 11.0665\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 18s 331ms/step - loss: 4.7738 - val_loss: 11.2315\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 16s 302ms/step - loss: 4.7331 - val_loss: 10.6039\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 4.6092 - val_loss: 10.7741\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 17s 315ms/step - loss: 4.7505 - val_loss: 10.8295\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 14s 270ms/step - loss: 4.8515 - val_loss: 10.8937\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 13s 246ms/step - loss: 4.9565 - val_loss: 10.9507\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 14s 256ms/step - loss: 4.6529 - val_loss: 10.9554\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 4.7802"
     ]
    }
   ],
   "source": [
    "mdl.fit(x_one_hot_tr, s_full_tr, epochs=1000, validation_data=(x_one_hot_te, s_full_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_oh = np.zeros((1, n_item))\n",
    "x_oh[0, 0] = 1\n",
    "\n",
    "mdl.predict(x_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "devenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
